{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bechirzammouri/translation-task-hf/blob/main/clm_task_hf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b2mmSgYdIGbw",
        "outputId": "fac294d9-d550-4700-c038-fd8bf3ca4408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.4-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading evaluate-0.4.4-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.4\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6edwMH5mHyf",
        "outputId": "b4533e35-7263-4006-b219-4fcf40876194"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `rw_hf_token` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `rw_hf_token`\n"
          ]
        }
      ],
      "source": [
        "! huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "knwnHFyKI-cJ",
        "outputId": "cc099138-71d8-4927-8237-e5a5a2bd2c15"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:86: UserWarning: \n",
            "Access to the secret `HF_TOKEN` has not been granted on this notebook.\n",
            "You will not be requested again.\n",
            "Please restart the session if you want to be prompted again.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "books = pd.read_parquet(\"hf://datasets/Helsinki-NLP/opus_books/en-fr/train-00000-of-00001.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wT-bwkUwaDRh"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "books = Dataset.from_pandas(books)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiDigQADnGFi",
        "outputId": "c714e66a-971a-4568-92db-c9556db1dba5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'translation'],\n",
              "    num_rows: 127085\n",
              "})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "books"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Wkzar_Qrm_c",
        "outputId": "d4166370-c42d-486f-b8e5-cd293623e122"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(127085, 2)\n"
          ]
        }
      ],
      "source": [
        "print(books.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yenQTNuNs0ae",
        "outputId": "89211697-f181-4732-dc64-48c63de51592"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "127085\n"
          ]
        }
      ],
      "source": [
        "print(books.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mARZWfg0rtAE"
      },
      "outputs": [],
      "source": [
        "books = books.train_test_split(test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DztEhMPdP5wi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeyEWo8RP3Lt",
        "outputId": "b3da46c9-bba6-462b-98ec-4a2fc497df76"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': ['58848', '45256', '49845', '64403', '85703'],\n",
              " 'translation': [{'en': 'But the witchcraft of the goat with the golden hoofs was a very innocent species of magic.',\n",
              "   'fr': 'Pourtant les sorcelleries de la chèvre aux pattes dorées étaient de bien innocentes malices.'},\n",
              "  {'en': '\"I mean that miserable d’Artagnan.\"',\n",
              "   'fr': \"-- Je veux parler de ce misérable d'Artagnan.\"},\n",
              "  {'en': 'He went to the small parlour, but the three millers had to be got out first, and during the whole time necessary for laying the cloth, Binet remained silent in his place near the stove. Then he shut the door and took off his cap in his usual way.',\n",
              "   'fr': 'Il se dirigea vers la petite salle; mais il fallut d’abord en faire sortir les trois meuniers; et, pendant tout le temps que l’on fut à mettre son couvert, Binet resta silencieux à sa place, auprès du poêle; puis il ferma la porte et retira sa casquette, comme d’usage.'},\n",
              "  {'en': 'It oozed.', 'fr': 'Ça suintait !'},\n",
              "  {'en': 'Madame Derville herself had her handkerchief pressed to her eyes.',\n",
              "   'fr': 'Mme Derville elle-même avait son mouchoir sur ses yeux.'}]}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "books[\"train\"][:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "c89caf05905c495398cb02893f1f4ffd",
            "240b50b0127a4a3e86a89b3f46fa5a17",
            "6d6c961187094b22bd0236ae0523527c",
            "14d4af4d4cab43f88dc03edbf581c907",
            "69a090affba44b9c980dfff0467ec627",
            "36b88ee1490841aeb65b3da17531fbb6",
            "b7519d3e177e49e49b942bc79d616a34",
            "28ac40614ce846c3ac3ba1c3467f7aa9",
            "d101fc88f2364c9f99b9e6b29af80914",
            "6a3f29ef7fd24bb3b20dcf256a5879f8",
            "6fcc608dafa24b89943581f8df65223f",
            "67cf68360ca9418285c26b42e3795559",
            "27a6e7176d5a438e95a9b8f185bd41fa",
            "f11c52257033445dba10afa5cc0c126f",
            "efa0a1de0e144e488aaf7a171d591abc",
            "5bdf534ffe75412b99e0f87286672aea",
            "58e9423988134a2587d507cbc4810077",
            "19846d938b664b098318524c1b3e9b86",
            "f240609b62034c32a962cc764b9ed7b2",
            "52d8f80d19e84bb3b9e0e9affb1e429b",
            "ff8d8da14d104f8f8305e5c86b915015",
            "a57e6e2aa32844cca5346d6c852666d5",
            "b7def0b848be4ebc8341c3e1f3d90d6f",
            "68e539c4b3124fde83b4587c99a320df",
            "e8af3909659f412f9d170421447ac67f",
            "35554a7b92ac49a7a0214bad72f7e6d4",
            "144d68992fbb4217a67bb2d8e9a97a84",
            "40bc678556c04fc29bf1f465df3d18c3",
            "e8af32005cc64f9685bd138a22a1e476",
            "09d794898ea447dcae46efa8bda16cbe",
            "a2feecc8e3b942a2a57796755c10834c",
            "f728c06ae6cc4d028da10ada8835c9fa",
            "b2da01e22e704e4d8ec8632c607bb557"
          ]
        },
        "id": "I2KtWULd8lNp",
        "outputId": "ed8cc3df-298e-4f90-9b44-3e1a9dbc6480"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c89caf05905c495398cb02893f1f4ffd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67cf68360ca9418285c26b42e3795559",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7def0b848be4ebc8341c3e1f3d90d6f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "#loading a tokenizer model T5\n",
        "checkpoint = \"google-t5/t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Thwp7HD49Dnd"
      },
      "outputs": [],
      "source": [
        "source_lang = \"en\"\n",
        "target_lang = \"fr\"\n",
        "prefix = \"translate English to French: \"\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = prefix + examples[\"translation\"][source_lang]\n",
        "    targets =  examples[\"translation\"][target_lang]\n",
        "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "9e5c455e3508499081e517badc059e60",
            "2928a6b02c97471882e09bc5159c806d",
            "7bbd053c062a47509deddec996e3979e",
            "2520bc32fb454727bed0cff59f233c0f",
            "2afaab76b3e747e4abdc8d91f1e5ab2c",
            "c724151677fc44b7b7980c13cc42822e",
            "1b58567051024758987f72a5b060c078",
            "41bb0e9d0cd44fd5ac2397f37c940ca2",
            "58a02f2f62d84bb5afd166a8994ada72",
            "29cc3edc83d14f4b83b0f9a5222202d7",
            "4421f4931a5546ec8e2eb8d5d3440f9a",
            "17de07f9930948419c1121722bea1942",
            "4c6bbe3523864f2ba65ee406df7bd185",
            "c12ea33fab304c879117562c39b9eb0f",
            "977739699d8440499f86ffdd2c20b79b",
            "0479e63ea0bb43a08b16310001db2edf",
            "53c5c9c7159d4a38bf440521d4c8cc48",
            "b97291e4ef454559a841c00a177f770d",
            "e756dd00ac4f4e8dab2eff751fc44654",
            "96f76a63c9374a7da4f73ef43a1be2f3",
            "805c401fc8664165a69b3176f874c61f",
            "7425638e37d34971ba7741eb13f4edbf"
          ]
        },
        "id": "miDSqxkwQY4i",
        "outputId": "577afb72-12dd-4fde-dd1b-7a25d7670b68"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e5c455e3508499081e517badc059e60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/101668 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17de07f9930948419c1121722bea1942",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/25417 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_books = books.map(preprocess_function)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQG7nUsPFA3J"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUC-XRxrVcVc"
      },
      "source": [
        "## defining evaluation metric and preparing the evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JHKjxzieVMy3",
        "outputId": "93ac527b-1123-43a1-d0dc-d39d4bb0d4e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2.0.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-3.2.0 sacrebleu-2.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "486ab94136c94f099e025fda38526870",
            "eef3ecc064b14f8f8f465c392c522d0c",
            "5a3e07a539284e6fba795b2efc814420",
            "720eecfd96794b34830f7aa288642733",
            "5707e69daf26476dadba46dc734be8c9",
            "4c6636a8cf4d41a09d6ed8956cdda4b4",
            "37c8ab9830174992b890c01355e5b426",
            "389d870bb8d44ce6929c4ab241f56bd8",
            "03fd225b91b246daaf0a92bea1042f5e",
            "803d563cef5147d883673e7d533ea628",
            "11428bff42ff47a9a690b481b6a5fdfc"
          ]
        },
        "id": "0vp4I9VsVAqO",
        "outputId": "b53bc848-8cad-4bc7-cbf5-7cb0dd1ac4ed"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "486ab94136c94f099e025fda38526870",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"sacrebleu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHJVRSysVa9A"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "  preds = [ pred.strip() for pred in preds]\n",
        "  labels = [ [ label.strip()] for label in labels]\n",
        "\n",
        "  return preds , labels\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "  preds , labels = eval_preds\n",
        "  if isinstance(preds, tuple):\n",
        "    preds = preds[0]\n",
        "\n",
        "  decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens = True)\n",
        "\n",
        "  labels = np.where(labels != -100 , labels , tokenizer.pad_token_id )\n",
        "  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens = True)\n",
        "\n",
        "  decoded_preds , decoded_labels = postprocess_text(decoded_preds , decoded_labels)\n",
        "\n",
        "  result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "  result = {\"bleu\" : result [\"score\"]}\n",
        "\n",
        "  prediction_lens = [np.count_nonzero(pred!= tokenizer.pad_token_id) for pred in preds]\n",
        "  result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "  result = { k: round(v,4) for k,v in result.items()}\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDHYxBazcgH7"
      },
      "source": [
        "\n",
        "\n",
        "*   Training T5 model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "701215033cbc4cccba8dda2976077c02",
            "d90d81a621a047aa915f6bfbc78fd074",
            "6278012cd33a4ae98bb693bd32f2e144",
            "9440ae5109b648d6b124c3756b2ca3d5",
            "e2d7ec2417624f62b46bfc7423558360",
            "a639aa1c5cb14cc183c37e20de364adf",
            "f6a5a15291ec46a6b9b55de67aa8fd34",
            "645773aba6e240c3afe3d622c98f4086",
            "acd3c9c60a834c3faf0d8f988187febd",
            "6e66db9b2f4d431cb5dad434b444d9ac",
            "ae30052b97f142c0b9f42680ae3ffed1",
            "4cb8d95d8fee41eebe44e943c2b8ffff",
            "cc72f5812c264d589b92689c6ad8976f",
            "6b888b0858864bbfba411de255631b57",
            "b37d0d8e03eb43259f2efb9497aecf2a",
            "23d482d352574a098e49f705dbbc726b",
            "1befb59179fb4a73a34bc491c32250b5",
            "16e590b37dd84c0f8439d2a0d1798414",
            "bfab9bc3485b48a0aeadf3daddd356fb",
            "6f02ffdfdd5f4401affc411416389097",
            "7758d490af63414db918befbb54d96d3",
            "499fa48b7be6404a93342e1fdfdded22",
            "519db45795634866a3359245e36a83d0",
            "f6d754bdb295493798380bdeef31aea8",
            "8385262048d545f59c4f6e121b1112a7",
            "6b6a025c57c2436eacf8a37ec30b9e80",
            "08f91a49fe41486fa8a3fce49a1816dd",
            "6d8997d4e9574467bedffff1a34c1f2b",
            "98ce5df9b4124aafa502f0d47663a84d",
            "6152c131a0514e998eeb3b7a6f43a47a",
            "8e52fc418f9d41049913779a10ce7ce9",
            "3ed4d78b2ef34effbf65ff3fcc184f01",
            "20fdcf3ca12b4b969e771e680780d0d4"
          ]
        },
        "id": "Wfd8VBGVcpSF",
        "outputId": "5aa46e99-0862-4187-d8eb-0dbaaf50e44e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "701215033cbc4cccba8dda2976077c02",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cb8d95d8fee41eebe44e943c2b8ffff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "519db45795634866a3359245e36a83d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DyxOVzACc5vV",
        "outputId": "14dcf65d-5f0b-4d6a-e825-34ee7c6a079a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-47-4077707952.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        }
      ],
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir = \"bechir_opus_books_model\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate = 2e-5,\n",
        "    per_device_train_batch_size = 16 ,\n",
        "    per_device_eval_batch_size= 16 ,\n",
        "    weight_decay=0.01 ,\n",
        "    save_total_limit=3 ,\n",
        "    num_train_epochs = 2,\n",
        "    predict_with_generate = True,\n",
        "    fp16 = True,\n",
        "    push_to_hub=True\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_books[\"train\"],\n",
        "    eval_dataset=tokenized_books[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "VNdgouAd8JYe",
        "outputId": "9dd904f4-c598-4c51-847d-764b4fb9e551"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='572' max='12710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  572/12710 2:29:46 < 53:09:34, 0.06 it/s, Epoch 0.09/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ER0u2l5rWS8N"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM ,AutoTokenizer\n",
        "\n",
        "text = \"translate English to French: Legumes share resources with nitrogen-fixing bacteria.\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bechirzammouri/bechir_opus_books_model\")\n",
        "inputs = tokenizer(text, return_tensors=\"pt\").input_ids\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"bechirzammouri/bechir_opus_books_model\")\n",
        "outputs = model.generate(inputs, max_new_tokens=40, do_sample=True, top_k=30, top_p=0.95)\n",
        "\n",
        "tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOSqlrZ0rT1C56gld7GtRIS",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
